---
layout: single 
title: "Can Watson navigate the medical literature?" 
category: quickbit
permalink: /node/28127
tags: [journals, artificial intelligence, open science, health, technology, metascience] 
comments: false 
author: John Hawks 
---

Last week, <em>Computerworld</em> reported that IBM's famous "Watson" supercomputer is moving to its next challenge: <a href="http://www.computerworld.com/s/article/9219937/IBM_s_Watson_supercomputer_to_diagnose_patients">prescribing cancer treatments for the WellPoint health plan.</a>

<blockquote>For example, Watson's analytics technology, used with Nuance's voice and clinical language understanding software, could help a physician consider all related texts, reference materials, prior cases, and latest knowledge in journals and medical literature when treating an illness. The analysis could quickly help physicians determine the best options for diagnosis and treatment.</blockquote>

<blockquote>"There are breathtaking advances in medical science and clinical knowledge [but] this clinical information is not always used in the care of patients," said Dr. Sam Nussbaum, WellPoint's Chief Medical Officer, in a statement.</blockquote>

Looks to me like a first step to removing humans from the decision-making chain. A.I., the ultimate bureaucrat. Plus, it can beat Ken Jennings on Jeopardy!

It occurs to me that the current medical literature is really poorly suited for AI trawling, in many ways. The data and results are obfuscated in many ways, and there's a strong publication bias toward positive results. Someone asked me just today about why open science is interesting to many of us, and the positive results bias struck me as a really important aspect. When you are keeping an open notebook, the negative results are right there along with the positives. Open notebook science might be better for AI-enhanced treatment plans. In any event, a more standard form of result reporting would be helpful. Why can't anyone run their own meta-analysis anytime she chooses?  

