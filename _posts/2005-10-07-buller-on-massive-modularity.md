---
layout: single 
title: "Buller on massive modularity" 
category: story
permalink: /weblog/reviews/behavior/buller/adapting_minds_chapter_4_modularity.html
tags: [minds, David Buller, evolutionary psychology, behavior] 
comments: false 
author: John Hawks 
---

<p>
Chapter 4 of David Buller's <a href="http://www.amazon.com/exec/obidos/redirect?path=ASIN/0262025795&amp;link_code=as2&amp;camp=1789&amp;tag=johnhawksanth-20&amp;creative=9325"><i>Adapting Minds : Evolutionary Psychology and the Persistent Quest for Human Nature</i></a> is a critique of the concept of massive modularity applied to the human mind. To me, this chapter is weaker than <a href="weblog/reviews/behavior/buller/adapting_minds_chapter_3.html">chapter 3, on adaptation</a>, not because the critique is necessarily wrong but because the examples are less compelling. 
</p>

<!-- more -->

<p>
The idea of massive modularity is that the brain has domain-specific processing circuits for a very large set of mental tasks that humans perform. According to evolutionary psychology, these circuits are the adaptations to past environments that allowed ancient humans to make adaptive decisions and pursue adaptive behaviors. Many EP proponents assert that there may be hundreds, or even thousands of such modules (hence, "massive" modularity). 
</p>

<p>
The differentiated brain circuits set these "domain-specific" modules apart from the hypothesis of "domain-general" intelligence, in which most mental tasks are performed by a single flexible mechanism. Thus the difference between massive modularity and domain-general intelligence is one of mechanism: in the first case, there are different circuits dedicated to different tasks; in the second, there is a single immense circuit that accomplishes a multiplicity of tasks. 
</p>

<p>
Buller sets out to attack the hypothesis of massive modularity on four bases: 
</p>

<p>
1. Humans don't have enough genes to build hundreds or thousands of cognitive modules. 
</p>

<p>
2. Neural development in the brain is complex and self-organizing on the basis of environmental inputs: they are <i>environmentally shaped</i>, not <i>genetically specified</i>. 
</p>

<p>
3. Well-defined sensory "modules" in the brain have extensive cross-modal communication, making it doubtful that less-well-understood and subtler cognitive modules could be functionally separate in any meaningful way. 
</p>

<p>
4. A domain-general mechanism, given appropriate innate information (such as which kinds of stimuli are important to attend to) can do anything that separate cognitive modules can do. 
</p>

<p>
Of this list, I think that the fourth is most important, and the fairest: 
</p>

<blockquote>The point is ... that Cosmides and Tooby fail to show that domain-general mechanisms can't generate domain-specific solutions because their arguments rely on a misrepresentation of how a domain-general problem-solver would function in different problem domains. Consequently, the crucial step in the argument for massive modularity is unsupported, so we're given no reason to believe that the mind can't be a general-purpose problem solver" (Buller 2005:146). </blockquote>

<p>
Buller applies the analogy of antibodies as a domain-general system: the immune system does not have a genetic specification for every antibody; they are built from a simple generalized assembly mechanism that adapts to different pathogens as necessary. Likewise, the brain builds its neural structures in response to environmental conditions in a way that can adapt effectively to them. 
</p>

<p>
But although Buller argues that the brain <i>might</i> function in this way, he provides little evidence that it <i>does</i> do so. And that is where the weaknesses in his evidence seem plain. 
</p>

<p>
The <i>number</i> of human genes is simply irrelevant. Clearly writing the book a few years ago, Buller claims that we have only 30,000 to 70,000 genes. It is now clear that the number is closer to 20,000. But this is no argument against the idea that the brain has a complex genetic design; any more than it can argue against the idea that the <i>body</i> has a complex genetic design, as it clearly does. We simply don't know how complex a structure can be built from any given number of genes. But we can make a guess. The operation of developmental and regulatory genes depends on the joint expression of multiple genes, each of which may form different overlapping expression gradients. Small numbers of genes expressed in different concentrations in different tissues lead to differentiation -- a cascade of signals causing genes to turn on or off and resulting in different structural elements. These combinations of genes are thus <i>combinatorial</i> in their effect, not additive. Thus, 20,000 genes can build structures that are <i>arbitrarily</i> complex. 
</p>

<p>
But could this have all happened during the short span of human evolution? Again, we have no idea what limits there may have been on evolutionary change in human brains. But consider that the development of structures in the brain takes very long compared to some aspects of development. The basic architecture of the body -- the limbs, number of verbebral segments, differentiation of tissue types, origins of internal organs and sensory organs -- all happens over the course off a few weeks in early embryos. In contrast, the migration of neural cells to different parts of the cortex, the formation of functional brain circuits, and the biochemical basis of normal adult cognition take several years. The migration of cells, the ease of forming new connections or severing old ones, the likelihood of neuron pruning or cell death, and the differentiation of circuits all depend on gene expression. This gene expression must vary among brain regions -- if it did not, then different brain functions such as vision, language learning, motor coordination, and others could not become effective at different times in ontogeny. There clearly are developmental windows and differences in developmental rates for <i>some</i> brain functions. What is not known is how extensive such ontogenetic structuring may be. But there is no reason to think that massive modularity <i>couldn't</i> have evolved during human evolution. 
</p>

<p>
Neural plasticity is certainly extensive. Buller does not mention some of the most profound examples, such as regaining function after brain damage and even hemispherectomy. But plasticity does not preclude the genetic specification of some neural functions. And two distinct pieces of evidence argue in favor of a strong genetic role. First, there are distinct functional areas of the neocortex. The most well-known (and defined) are the language areas, such as Broca's and Wernicke's areas. Indeed, Buller even sets language aside completely, as a "specially complex" case where modularity may be important to neural function. But language is not the only function that involved particular brain regions. And there are differences in the brain regions involved in certain functions between males and females. This kind of sexual dimorphism does not point to purely environmental causation for cognitive structure; it reflects the influence of genetic switches (like those discussed by Buller in chapter 3) on later brain development. 
</p>

<p>
The second evidence in favor of <i>some</i> genetic specification for human brains is the fact that other kinds of primates cannot be trained to do many human cognitive tasks. Now, Buller could argue (he does not) that the brain has some kind of gatekeeper function, that enables humans to make better or more effective use of cultural stimuli, and thereby renders humans different from chimpanzees and other apes despite being similarly domain-general in cognitive processing. I'm not sure that I wouldn't argue this myself -- although I would be hard-pressed to explain why such "gatekeeper" functions would not <i>themselves</i> be human-specific cognitive <i>modules</i>. 
</p>

<p>
The key point is that human cognition is not free of some genetic influences. It is therefore not implausible that human brains <i>could</i> have evolved semi-discrete modular circuits to accomplish specific, fitness-related tasks. Indeed, if there were strong selection in favor of some behavior or decision, humans would conceivably be much better off being able to adapt by evolving dedicated circuits to conduct the behavior or make the decision rapidly and accurately. 
</p>

<p>
If there is a theoretical objection, it must be framed in terms that explain why selection would not lead to such functional specificity. I can't think of any reason why it should not be possible in priniciple to evolve massive modularity. Partly this is because human brains are quite modular -- we have different cognitive circuits to handle different sensory inputs, perception, emotion, sleep, and so on. Some of these greatly overlap in their area and function, but it is not accurate to say that such functions are accomplished by domain-general intelligence. My own opinion is that human cognition is domain-general because such a process works better with cultural systems of knowledge. But demonstrating this requires empirical understanding of human cognition, not arguments about gene number and brain construction. 
</p>

<h4>The Wason selection test</h4>

<p>
For this reason, Buller's critique of the empirical evidence for modularity is the better part of the chapter. The critique of the Wason selection test is the majority and the strongest part. There are lots of reasons why these tests don't necessarily yield the proposed information about human mental structures; Buller strikes upon several of these. 
</p>

<p>
Throughout the book, Buller is concerned with the relation of theoretical grounding and empirical evidence. The recurring point is that evolutionary psychology claims a theoretical grounding from evolutionary theory for their hypotheses, and that EP also claims strong empirical evidence. For Buller, it is not enough to challenge the empirical studies, because one might easily argue that although some <i>particular</i> experiment may be flawed, the theory is still compelling. So he is at pains to detail why both the theory and the evidence are weak. 
</p>

<p>
Buller's argument (on pages 171 and 172) relating to the Wason tests as evidence for a cheater detection module begins with a theoretical point. He notes the origin of the problem of cheater detection in Trivers' work, which outlined the necessary conditions for reciprocal altruism to evolve. Reciprocal altruism is a <i>social exchange</i>, in which two actors both collaborate in conditions that give both actors a benefit and exact from both actors a cost. But the Wason selection tasks used by evolutionary psychologists do not involve social exchange, but instead <i>social contracts</i>, in which one actor is obligated to perform some action (i.e. a cost) in order to obtain a benefit. 
</p>

<blockquote>There is, therefore, a disconnect between the <i>theoretical support</i> for the cheater-detection module and the <i>empirical results</i> that purportedly provide evidence of its existence. The theory behind the cheater-detection module should lead us to expect a mechanism that is specialized in detecting chaters <i>in the domain of social exchanges</i>. But the experimental results that purportedly support the existence of a cheater-detection module involve detecting cheaters <i>in the domain of social contracts.</i> ... [A]lthough we have a well-developed theoretical understanding of how social exchanges evolved, we have no comparable theoretical understanding of how social contracts evolved (and Evolutionary Psychologists offer no theory about the evolution of social contracts) (Buller 2005:172).</blockquote>

<p>
It is fair to ask what the difference between social exchange and social contracts really is, since they clearly are similar to each other. Buller does not explain this well, so one may be tempted to read his argument as mere semanticism. But there is a key difference: a social contract can involve <i>any</i> combination of cost and benefit to the individual. The punishment may fit the crime, as it were, or it may not: the rules are the same either way. It is this breadth that allows evolutionary psychologists to design situations that are "culturally distant" from their research subjects -- they can claim that cassava root is a great aphrodisiac and that sexually active men must have tattoos, and the rules are the rules, period. 
</p>

<p>
In contrast, a social exchange is vastly narrower: as modeled by Trivers and applied to human evolution, a social exchange is one in which the benefits to each individual must outweigh the individual's cost. Only a comparatively limited set of interactions can fit this criterion, which was Trivers' point concerning reciprocal altruism. As a system, such exchange may be a subset of social contracts, but human society gives rise to many kinds of contracts that cannot validly be considered as examples of social exchange. The rules governing such contracts are imposed from above by society. Buller does not make this explicit, but it seems evident that a "module" for enforcing social contracts need have little logically in common with a "module" for conducting reciprocal exchange. His point is that there is no theory to account for the former, while the empirical data do not fit the latter. 
</p>

<h4>Deontic conditionals</h4>

<p>
After this theoretical point, Buller embarks on an explanation for the observed Wason selection test results that does not involve specialized cognitive modules. The first aspect of this is the apparent "content effect" in the tests: people "get the right answers" more often when the task involves social contracts than when the task involves abstract numbers, or even social situations that do not involve contracts. 
</p>

<p>
It seems to me that anyone who takes Chomskian generative grammar seriously must recognize the possibility that two sentences with apparently similar <i>surface</i> forms "if P then Q" might well have different <i>deep</i> structures. Fodor and Buller assert that exactly this is the case: that the indicative conditionals take the form of scientific propositions ("If you eat duiker meat, then you have found ostrich eggshell"), whereas the social contract deontic conditionals take the form of obligations ("You cannot eat cassava root if you do not have the tattoo"). We should be no more surprised at a person interpreting these two sentences in different ways than we would be at a person interpreting many aspects of language. 
</p>

<p>
Of course, another way of problematizing the Wason selection test results is to notice the extremely poor performance of most people on the arbitrary "indicatively conditional" relations. The problem would not be to explain why people do <i>well</i> on the social contract problems, but why instead they do <i>poorly</i> on the abstract problems. According to evolutionary psychology, it is because people are not adapted to solve these abstract problems. 
</p>

<p>
According to Buller, the poor performance on arbitrary problems is due to a lack of sufficient information. 
</p>

<blockquote>Indicative conditionals that embody arbitray connections between antecedent and consequent conditions, and that are presented within very sketchy and artificial background stories, do not appear with a sufficient number of the informational properteies on which subjects normally rely in representing the logical type of a conditional utterance (Buller 2005:180). </blockquote>

<p>
Buller discusses experiments that confirm this view, in which people perform better with more information. I can confirm this myself; as I have used the Wason test on classes to illustrate it, students do better once they understand how the test works, practice being another way of providing background. 
</p>

<p>
But there is another possibility that Buller does not raise, but is discussed by Jonathan Lowe in his <i>An introduction to the philosophy of mind</i>. When people are presented with arbitrary information and asked to generalize it, a perfectly valid approach is <i>inductive reasoning</i>. The Wason selection test assumes that a deductive approach is the correct one. But deductive logic in the face of unfamiliar data can be silly: 
</p>

<blockquote>Consider, by way of analogy, how a scientist might attempt to confirm or falsify a general empirical hypothesis, such as the hypothesis that if a bird is a member of the crow family, then it is black. Clearly, he would do well to examine crows to see if they are black .... But it would be foolish of him to examine non-black things, just on the off-chance that he might happen upon one which is a crow and thereby falsify the hypothesis (Lowe 2000:198). </blockquote>

<p>
According to this view, the central issue is one of practical reasoning. In practice, it combines with the lack of background information: most people use deductive reasoning only with reference to well-understood problems that they have much experience with. This is why Sherlock Holmes stories continue to be entertaining; he uses deductive reasoning in situations where most people would not. But people can hardly be faulted for using practical inductive reasoning in a situation where deduction has not been keyed by background information. 
</p>

<p>
<a href="weblog/reviews/behavior/buller/">More on <i>Adapting Minds</i></a>
</p>

<h4>References:</h4>

<p class="cite">Buller DJ. 2005. Adapting Minds : Evolutionary Psychology and the Persistent Quest for Human Nature. Bradford Books, New York. <a href="http://www.amazon.com/exec/obidos/redirect?path=ASIN/0262025795&amp;link_code=as2&amp;camp=1789&amp;tag=johnhawksanth-20&amp;creative=9325">Amazon</a></p>

<p class="cite">Lowe EJ. 2000. An introduction to the philosophy of mind. Cambridge University Press, Cambridge UK. </p>


