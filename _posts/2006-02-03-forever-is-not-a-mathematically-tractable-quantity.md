---
layout: single 
title: "&quot;&#39;Forever&#39; is not a mathematically tractable quantity&quot;" 
category: story
permalink: /weblog/topics/minds/logic/bayesian_article_economist_2006.html
tags: [mind] 
comments: false 
author: John Hawks 
---


<p>
That's my favorite line from <a href="http://economist.com/science/displayStory.cfm?story_id=5354696">this article in the <I>Economist</i></a> about Bayesian logic. 
</p>

<p>
From <a href="http://en.wikipedia.org/wiki/Bayesian_logic">Wikipedia</a>, a short introduction to Bayesian logic: 
</p>

<blockquote>For example, Laplace estimated the mass of Saturn using Bayesian methods. However, on the frequency interpretation of probability the laws of probability cannot be applied to this problem. This is because the mass of Saturn isn't a well defined random experiment or sample. From what population is the mass of Saturn taken? In what sense is Saturn picked at random from that population? Similarly, when comparing two hypotheses and using the same information, frequency methods would typically result in the rejection or non-rejection of the original hypothesis with a particular degree of confidence, while Bayesian methods would yield statements that one hypothesis was more probable than the other or that the expected loss associated with one was less than the expected loss of the other.</blockquote>

<p>
The <i>Economist</i> article is a good short introduction to what Bayesian logic is, and it follows some interesting research that indicates that human minds are especially good at it: 
</p>

<blockquote>Dr Griffiths and Dr Tenenbaum conducted their experiment by giving individual nuggets of information to each of the participants in their study (of which they had, in an ironically frequentist way of doing things, a total of 350), and asking them to draw a general conclusion. For example, many of the participants were told the amount of money that a film had supposedly earned since its release, and asked to estimate what its total "gross" would be, even though they were not told for how long it had been on release so far.</blockquote>

<blockquote>Besides the returns on films, the participants were asked about things as diverse as the number of lines in a poem (given how far into the poem a single line is), the time it takes to bake a cake (given how long it has already been in the oven), and the total length of the term that would be served by an American congressman (given how long he has already been in the House of Representatives). All of these things have well-established probability distributions, and all of them, together with three other items on the list -- an individual's lifespan given his current age, the run-time of a film, and the amount of time spent on hold in a telephone queuing system -- were predicted accurately by the participants from lone pieces of data.</blockquote>

<p>
By "accurately", they appear to mean that the prior distribution was reconstructable from the responses of the 350 people, not that every person guessed the right answer. 
</p>

<p>
The "forever" line comes from this passage: 
</p>

<blockquote>There were only two exceptions, and both proved the general rule, though in different ways. Some 52% of people predicted that a marriage would last forever when told how long it had already lasted. As the authors report, "this accurately reflects the proportion of marriages that end in divorce", so the participants had clearly got the right idea. But they had got the detail wrong. Even the best marriages do not last forever. Somebody dies. And "forever" is not a mathematically tractable quantity, so Dr Griffiths and Dr Tenenbaum abandoned their analysis of this set of data.</blockquote>

<p>
Personally, I think it's romantic that 52 percent of people predicted that marriage would last forever!
</p>

<p>
I suppose that helps to underlie the last two paragraphs: 
</p>

<blockquote>How the priors are themselves constructed in the mind has yet to be investigated in detail. Obviously they are learned by experience, but the exact process is not properly understood. Indeed, some people suspect that the parsimony of Bayesian reasoning leads occasionally to it going spectacularly awry, with whatever process it is that forms the priors getting further and further off-track rather than converging on the correct distribution.</blockquote>

<blockquote>That might explain the emergence of superstitious behaviour, with an accidental correlation or two being misinterpreted by the brain as causal. A frequentist way of doing things would reduce the risk of that happening. But by the time the frequentist had enough data to draw a conclusion, he might already be dead.</blockquote>

<p>
Which may help to explain why it takes a certain size and structure of population to develop science -- probably including writing, so it's harder to ignore information that someone else collects. 
</p>

<p>
Anyway, read <a href="http://economist.com/science/displayStory.cfm?story_id=5354696">the article</a> to find out the problem people had guessing the length of the reigns of Egyptian Pharaohs. 
</p>

